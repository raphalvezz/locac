{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo de Baseline Supervisionado (SL) - Previsão de Lucro\n",
        "\n",
        "**Objetivo:** Treinar um modelo de baseline (LGBM Regressor) para prever o `Lucro_Real` com base no contexto da campanha e nas features do produto digital.\n",
        "\n",
        "**Metodologia:**\n",
        "1.  **Carregar Artefatos:** Carrega o dataset (`.csv`) e os pré-processadores (`.joblib`) gerados pelo `Generator_NEW.py`.\n",
        "2.  **Preparar Dados:** Define `X` (features) e `y` (alvo) e aplica os pré-processadores carregados (OHE, Scaler).\n",
        "3.  **Treinar Modelo:** Divide os dados em treino/teste e treina um `LGBMRegressor`.\n",
        "4.  **Avaliar (Global):** Calcula as métricas globais (MAE, RMSE, R²).\n",
        "5.  **Avaliar (Granular):** Analisa o desempenho do modelo por segmentos (ex: `Tier`, `Tipo_Produto`).\n",
        "6.  **Explicar (SHAP):** Usa SHAP para entender quais features mais impactam a previsão de lucro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import lightgbm as lgb\n",
        "import shap\n",
        "import d3rlpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Carregando artefatos gerados pelo Generator...\")\n",
        "\n",
        "df_sl = pd.read_csv(\"sl_dataset_combined.csv\")\n",
        "print(f\"✓ Dataset 'sl_dataset_combined.csv' carregado ({len(df_sl)} linhas)\")\n",
        "\n",
        "encoder_sl = joblib.load(\"sl_encoder.joblib\")\n",
        "print(\"✓ Encoder 'sl_encoder.joblib' carregado\")\n",
        "\n",
        "scaler_estado = joblib.load(\"sl_scaler_estado.joblib\")\n",
        "print(\"✓ Scaler 'sl_scaler_estado.joblib' carregado\")\n",
        "\n",
        "scaler_lucro = joblib.load(\"sl_scaler_lucro.joblib\")\n",
        "print(\"✓ Scaler 'sl_scaler_lucro.joblib' carregado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_column = \"Lucro_Real\"\n",
        "\n",
        "X_raw = df_sl.drop(columns=[target_column])\n",
        "y_raw = df_sl[[target_column]]\n",
        "\n",
        "print(f\"Alvo (y): {target_column}\")\n",
        "print(f\"Total de features de entrada (X): {X_raw.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preparar Dados (Definir X e y, Pré-processar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nAplicando pré-processamento (encoder + scaler de estado)...\")\n",
        "\n",
        "X_encoded = encoder_sl.transform(X_raw)\n",
        "X_processed = scaler_estado.transform(X_encoded)\n",
        "\n",
        "y_processed = scaler_lucro.transform(y_raw.values.reshape(-1, 1))\n",
        "\n",
        "print(f\"Formato final de X_processed: {X_processed.shape}\")\n",
        "print(f\"Formato final de y_processed: {y_processed.shape}\")\n",
        "\n",
        "# nomes pós-OHE para SHAP:\n",
        "feature_names_processed = encoder_sl.get_feature_names_out()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Treinar Modelo (LGBMRegressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nAplicando pré-processamento (encoder + scaler de estado)...\")\n",
        "\n",
        "X_encoded = encoder_sl.transform(X_raw)\n",
        "X_processed = scaler_estado.transform(X_encoded)\n",
        "\n",
        "y_processed = scaler_lucro.transform(y_raw.values.reshape(-1, 1))\n",
        "\n",
        "print(f\"Formato final de X_processed: {X_processed.shape}\")\n",
        "print(f\"Formato final de y_processed: {y_processed.shape}\")\n",
        "\n",
        "# nomes pós-OHE para SHAP:\n",
        "feature_names_processed = encoder_sl.get_feature_names_out()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Avaliar (Global)\n",
        "\n",
        "Calcula as métricas e reverte o scaling para R$ (conforme snippet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_segments(segment_col: str,\n",
        "                     X_test_df_orig: pd.DataFrame,\n",
        "                     y_true_real: np.ndarray,\n",
        "                     y_pred_real: np.ndarray):\n",
        "    print(f\"\\n--- Métricas por Segmento: {segment_col} ---\")\n",
        "\n",
        "    if segment_col not in X_test_df_orig.columns:\n",
        "        print(f\"AVISO: Coluna '{segment_col}' não encontrada. Pulando.\")\n",
        "        return\n",
        "\n",
        "    df_eval = X_test_df_orig.copy()\n",
        "    df_eval[\"y_true_real\"] = y_true_real.flatten()\n",
        "    df_eval[\"y_pred_real\"] = y_pred_real.flatten()\n",
        "\n",
        "    for segment_value in df_eval[segment_col].unique():\n",
        "        group = df_eval[df_eval[segment_col] == segment_value]\n",
        "\n",
        "        mae_seg = mean_absolute_error(group[\"y_true_real\"], group[\"y_pred_real\"])\n",
        "        rmse_seg = mean_squared_error(group[\"y_true_real\"], group[\"y_pred_real\"], squared=False)\n",
        "        r2_seg = r2_score(group[\"y_true_real\"], group[\"y_pred_real\"])\n",
        "\n",
        "        print(f\"\\nSegmento: {segment_col} = {segment_value} ({len(group)} amostras)\")\n",
        "        print(f\"  MAE (R$): {mae_seg:,.2f}\")\n",
        "        print(f\"  RMSE (R$): {rmse_seg:,.2f}\")\n",
        "        print(f\"  R²: {r2_seg:.2%}\")\n",
        "\n",
        "print(\"=\"*30)\n",
        "print(\"MÉTRICAS GRANULARES (Baseline SL)\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "analyze_segments(\"Product_Tier\", X_test_orig_df, y_true_real, y_pred_real)\n",
        "analyze_segments(\"Offer_Type\", X_test_orig_df, y_true_real, y_pred_real)\n",
        "analyze_segments(\"Pricing_Model\", X_test_orig_df, y_true_real, y_pred_real)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Avaliar (Granular por Segmento)\n",
        "\n",
        "Análise de desempenho granular, conforme `prompt + alterações (1).pdf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nCalculando valores SHAP para explicabilidade...\")\n",
        "\n",
        "explainer = shap.TreeExplainer(lgbm_model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "print(\"✓ Valores SHAP calculados. Gerando gráfico de resumo...\")\n",
        "shap.summary_plot(shap_values, X_test, feature_names=feature_names_processed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Explicar (SHAP)\n",
        "\n",
        "Análise de importância das features, conforme `prompt + alterações (1).pdf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nCalculando valores SHAP para explicabilidade...\")\n",
        "\n",
        "# 1. Criar o explicador\n",
        "explainer = shap.TreeExplainer(lgbm_model)\n",
        "\n",
        "# 2. Calcular os valores SHAP (usamos X_test processado)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "print(\"✓ Valores SHAP calculados. Gerando gráfico de resumo...\")\n",
        "\n",
        "# 3. Gerar o gráfico de resumo\n",
        "# Note: Passamos X_test (processado) e os nomes das features (pós-processamento)\n",
        "shap.summary_plot(shap_values, X_test, feature_names=feature_names_processed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
