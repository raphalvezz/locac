{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo de Baseline Supervisionado (SL) - Previsão de Lucro\n",
        "\n",
        "**Objetivo:** Treinar um modelo de baseline (LGBM Regressor) para prever o `Lucro_Real` com base no contexto da campanha e nas features do produto digital.\n",
        "\n",
        "**Metodologia:**\n",
        "1.  **Carregar Artefatos:** Carrega o dataset (`.csv`) e os pré-processadores (`.joblib`) gerados pelo `Generator_NEW.py`.\n",
        "2.  **Preparar Dados:** Define `X` (features) e `y` (alvo) e aplica os pré-processadores carregados (OHE, Scaler).\n",
        "3.  **Treinar Modelo:** Divide os dados em treino/teste e treina um `LGBMRegressor`.\n",
        "4.  **Avaliar (Global):** Calcula as métricas globais (MAE, RMSE, R²).\n",
        "5.  **Avaliar (Granular):** Analisa o desempenho do modelo por segmentos (ex: `Tier`, `Tipo_Produto`).\n",
        "6.  **Explicar (SHAP):** Usa SHAP para entender quais features mais impactam a previsão de lucro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Carregando artefatos gerados pelo Generator...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import lightgbm as lgb\n",
        "import shap\n",
        "import d3rlpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Carregando artefatos gerados pelo Generator...\")\n",
        "\n",
        "# encoder novo, gerado pelo Generator_NEW.py\n",
        "encoder_sl = joblib.load(\"sl_ohe_encoder.joblib\")\n",
        "\n",
        "# scaler de estado – esse nome já bate com o generator\n",
        "scaler_estado = joblib.load(\"sl_scaler_estado.joblib\")\n",
        "\n",
        "# se o generator salvou os dois alvos:\n",
        "scaler_estado = joblib.load(\"sl_scaler_estado.joblib\")\n",
        "df_sl = pd.read_csv(\"sl_dataset_combined.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Features que o encoder_sl viu no fit:\n",
            "['Regiao', 'Plataforma', 'Tier', 'Idade', 'Genero', 'Conteudo', 'Tipo_Produto', 'Modelo_Cobranca', 'Complexidade_Oferta']\n",
            "\n",
            "Colunas atuais do df_sl:\n",
            "['Regiao', 'Plataforma', 'Tier', 'Idade', 'Genero', 'Conteudo', 'Tipo_Produto', 'Modelo_Cobranca', 'Complexidade_Oferta', 'Orcamento', 'Preco_Amostra', 'Lucro_Real']\n"
          ]
        }
      ],
      "source": [
        "# 3) Ver quais features o encoder espera\n",
        "print(\"\\nFeatures que o encoder_sl viu no fit:\")\n",
        "print(list(encoder_sl.feature_names_in_))\n",
        "\n",
        "print(\"\\nColunas atuais do df_sl:\")\n",
        "print(list(df_sl.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\MDF\\Downloads\\locac-main\\.venv\\Scripts\\python.exe\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dimensões brutas:\n",
            "X_raw: (50000, 9)\n",
            "y_raw: (50000, 1)\n"
          ]
        }
      ],
      "source": [
        "# 4) Definir alvo e features EXATAMENTE com base no encoder\n",
        "target_column = \"Lucro_Real\"   # é o lucro que queremos prever\n",
        "feature_cols = list(encoder_sl.feature_names_in_)\n",
        "\n",
        "# Garante que todas as features existem no dataset\n",
        "missing = [c for c in feature_cols if c not in df_sl.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"As seguintes colunas esperadas pelo encoder não existem no df_sl: {missing}\")\n",
        "\n",
        "X_raw = df_sl[feature_cols].copy()\n",
        "y_raw = df_sl[target_column].values.reshape(-1, 1)\n",
        "\n",
        "print(f\"\\nDimensões brutas:\")\n",
        "print(f\"X_raw: {X_raw.shape}\")\n",
        "print(f\"y_raw: {y_raw.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preparar Dados (Definir X e y, Pré-processar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Aplicando pré-processamento (apenas encoder categórico)...\n",
            "Formato final de X_processed: (50000, 32)\n",
            "Formato final de y_processed: (50000, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nAplicando pré-processamento (apenas encoder categórico)...\")\n",
        "\n",
        "# 1) One-hot nas 9 colunas categóricas\n",
        "X_encoded = encoder_sl.transform(X_raw)\n",
        "\n",
        "# 2) NÃO usar o scaler de estado por enquanto\n",
        "X_processed = X_encoded\n",
        "\n",
        "# 3) Alvo em R$ mesmo (sem scaler), mais simples e ótimo pro TCC\n",
        "y_processed = y_raw\n",
        "\n",
        "print(f\"Formato final de X_processed: {X_processed.shape}\")\n",
        "print(f\"Formato final de y_processed: {y_processed.shape}\")\n",
        "\n",
        "# Para SHAP: nomes das colunas após o one-hot\n",
        "feature_names_processed = encoder_sl.get_feature_names_out()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Treinar Modelo (LGBMRegressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Treino: 40000 amostras\n",
            "Teste:  10000 amostras\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 64\n",
            "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 1928.599713\n",
            "✓ Modelo LGBM treinado.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_processed, y_processed, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Treino: {X_train.shape[0]} amostras\")\n",
        "print(f\"Teste:  {X_test.shape[0]} amostras\")\n",
        "\n",
        "lgbm_model = lgb.LGBMRegressor(\n",
        "    random_state=42,\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=31,\n",
        ")\n",
        "\n",
        "lgbm_model.fit(X_train, y_train.ravel())\n",
        "print(\"✓ Modelo LGBM treinado.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Avaliar (Global)\n",
        "\n",
        "Calcula as métricas e reverte o scaling para R$ (conforme snippet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============================\n",
            "MÉTRICAS GLOBAIS (Baseline SL)\n",
            "==============================\n",
            "MAE (R$):  371.16\n",
            "RMSE (R$): 623.08\n",
            "R²:        89.53%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "y_pred = lgbm_model.predict(X_test).reshape(-1, 1)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"=\"*30)\n",
        "print(\"MÉTRICAS GLOBAIS (Baseline SL)\")\n",
        "print(\"=\"*30)\n",
        "print(f\"MAE (R$):  {mae:,.2f}\")\n",
        "print(f\"RMSE (R$): {rmse:,.2f}\")\n",
        "print(f\"R²:        {r2:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nCalculando valores SHAP para explicabilidade...\")\n",
        "\n",
        "explainer = shap.TreeExplainer(lgbm_model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "print(\"✓ Valores SHAP calculados. Gerando gráfico de resumo...\")\n",
        "shap.summary_plot(shap_values, X_test, feature_names=feature_names_processed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Explicar (SHAP)\n",
        "\n",
        "Análise de importância das features, conforme `prompt + alterações (1).pdf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nCalculando valores SHAP para explicabilidade...\")\n",
        "\n",
        "# 1. Criar o explicador\n",
        "explainer = shap.TreeExplainer(lgbm_model)\n",
        "\n",
        "# 2. Calcular os valores SHAP (usamos X_test processado)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "print(\"✓ Valores SHAP calculados. Gerando gráfico de resumo...\")\n",
        "\n",
        "# 3. Gerar o gráfico de resumo\n",
        "# Note: Passamos X_test (processado) e os nomes das features (pós-processamento)\n",
        "shap.summary_plot(shap_values, X_test, feature_names=feature_names_processed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
